# ============================================================
# MNEMOSYNE -- Configuration
# ============================================================
# Copy this file to .env and fill in your values.
#   cp .env.example .env

# [REQUIRED] Select your LLM provider
# Options: google | anthropic | groq | openrouter | openai | ollama
LLM_PROVIDER=google

# [OPTIONAL] Override the default model for your provider
# Leave empty to use the provider's default model.
# LLM_MODEL=

# ── Provider API Keys ─────────────────────────────────────
# Set ONLY the key for your chosen provider.

# Google Gemini (default: gemini-2.0-flash)
GOOGLE_API_KEY=your-api-key-here

# Anthropic Claude (default: claude-sonnet-4-20250514)
# ANTHROPIC_API_KEY=your-api-key-here

# Groq (default: llama-3.3-70b-versatile)
# GROQ_API_KEY=your-api-key-here

# OpenRouter (default: google/gemini-2.0-flash-exp:free)
# OPENROUTER_API_KEY=your-api-key-here

# OpenAI (default: gpt-4o-mini)
# OPENAI_API_KEY=your-api-key-here

# ── Ollama (local, no API key needed) ─────────────────────
# OLLAMA_BASE_URL=http://localhost:11434

# ── ChromaDB ──────────────────────────────────────────────
# CHROMA_DB_PATH=.mnemosyne/chroma
# COLLECTION_NAME=mnemosyne
